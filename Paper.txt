import numpy as np
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.layers import Input, Flatten, Dense, Dropout
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix, classification_report

train_url ="/content/drive/MyDrive/col/train"
test_url = "/content/drive/MyDrive/col/test"

img_size = 256
batch_size = 32

# Data Augmentation
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=True, brightness_range=[0.7, 1.3], channel_shift_range=0.1, fill_mode='nearest')
test_datagen = ImageDataGenerator(rescale=1./255)

#Train and Test Generator
train_generator = train_datagen.flow_from_directory(train_url, target_size=(img_size, img_size), batch_size=batch_size, class_mode='binary')
test_generator = test_datagen.flow_from_directory(test_url, target_size=(img_size, img_size), batch_size=batch_size, class_mode='binary')

#Display Images from Classes
sample_images, sample_labels = train_generator.next()
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(sample_images[i])
    plt.title(f"Binary Image: {int(sample_labels[i])}")
    plt.axis('off')
plt.show()


# Convert class labels to binary representation for the entire dataset
binary_labels = train_generator.classes
num_classes = len(train_generator.class_indices)
binary_labels_binary = np.zeros((len(train_generator.labels), num_classes))

for i, label in enumerate(binary_labels):
    binary_labels_binary[i, label] = 1

print("Binary Representation of Class Labels:")
print(binary_labels_binary)


# VGG16 model
vgg = VGG16(input_shape=(img_size, img_size, 3), weights='imagenet', include_top=False)

for layer in vgg.layers:
    layer.trainable = False

x = Flatten()(vgg.output)
x = Dropout(0.8)(x)
x = Dense(46, activation='relu', kernel_regularizer=l2(0.001))(x)
x = Dropout(0.6)(x)
prediction = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))(x)

# Model
model = Model(inputs=vgg.input, outputs=prediction)
model.summary()

# Learning rate 
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0001, decay_steps=10000, decay_rate=0.9)

# Compile model 
model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])

# Early Stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Class weights calculation
class_weights = {0: 1, 1: len(binary_labels) / np.sum(binary_labels)}

# Training
r = model.fit(train_generator, validation_data=test_generator, epochs=30, steps_per_epoch=len(train_generator), validation_steps=len(test_generator), callbacks=[early_stopping], class_weight=class_weights)

# Evaluation model
evaluate_result = model.evaluate(test_generator)
loss_percentage = evaluate_result[0] * 100
accuracy_percentage = evaluate_result[1] * 100
print("Evaluation Metrics:")
print(f"Loss: {loss_percentage:.2f}%, Accuracy: {accuracy_percentage:.2f}%")

# Plot training and validation accuracy
plt.plot(r.history['accuracy'], label='Train Accuracy')
plt.plot(r.history['val_accuracy'], label='Test Accuracy')
plt.legend()
plt.show()

# Plot training and validation loss
plt.plot(r.history['loss'], label='Train Loss')
plt.plot(r.history['val_loss'], label='Test Loss')
plt.legend()
plt.show()


# Confusion matrix
y_pred = model.predict(test_generator)
y_pred_binary = np.round(y_pred)
y_true_binary = test_generator.classes
cm = confusion_matrix(y_true_binary, y_pred_binary)

# Classification report
target_names = [str(cls) for cls in range(2)]  # Update with your class names
print("Classification Report:")
print(classification_report(y_true_binary, y_pred_binary, target_names=target_names))

# Plot confusion matrix
plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, cmap="Blues", xticklabels=target_names, yticklabels=target_names)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()